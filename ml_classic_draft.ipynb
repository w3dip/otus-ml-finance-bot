{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-27T22:23:49.073324Z",
     "start_time": "2025-01-27T22:23:48.315691Z"
    }
   },
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Обучение модели случайного леса на тренировочной выборке\n",
    "rfc_model = RandomForestRegressor(\n",
    "    #n_estimators=100,            # Количество деревьев в лесу. Большее количество деревьев может улучшить точность, но увеличивает время обучения.\n",
    "    #max_depth=5,                 # Максимальная глубина каждого дерева. Ограничение глубины снижает вероятность переобучения.\n",
    "    #min_samples_split=200,        # Минимальное число образцов для разделения узла. Большее значение предотвращает разделение узлов с малым числом выборок.\n",
    "    #min_samples_leaf=2,          # Минимальное количество выборок, которое должно находиться в каждом листе. Увеличение значения делает модель более устойчивой.\n",
    "    #max_features='sqrt',         # Максимальное количество признаков, используемых при поиске лучшего разбиения. \"sqrt\" берёт корень из общего числа признаков.\n",
    "    #max_leaf_nodes=20,           # Максимальное число листьев в каждом дереве. Ограничивает количество конечных узлов, упрощая структуру дерева.\n",
    "    #min_impurity_decrease=0.01,  # Минимальное уменьшение нечистоты, требуемое для разделения. Предотвращает создание слишком мелких узлов.\n",
    "    #bootstrap=False,              # Использовать бутстрэп (выборка с возвращением) для создания деревьев. Это повышает устойчивость модели.\n",
    "    random_state=COMMON_CONFIG.SEED              # Устанавливает начальное значение для генератора случайных чисел, что обеспечивает воспроизводимость результатов.\n",
    ")\n",
    "rfc_model.fit(X_train_selected, y_train)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "X_train_selected",
   "id": "94a7b3e4f01bbf38"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "y_train",
   "id": "8297e3e34dbfc7d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "y_pred = pd.DataFrame(rfc_model.predict(X_test_selected), index=X_test_selected.index, columns=['predicted_close'])\n",
    "y_pred"
   ],
   "id": "2066f727ed009130"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "all_predictions = y_pred#['predicted_close']\n",
    "all_targets = y_test#['close']\n",
    "plot(all_predictions, all_targets, \"ML model Predictions vs. Actual\")"
   ],
   "id": "4af2a16415858eda"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "cb_model = cb.CatBoostRegressor(\n",
    "    n_estimators=1000,             # Общее количество деревьев (итераций). Меньшее значение снижает вероятность переобучения.\n",
    "    random_state=COMMON_CONFIG.SEED,               # Устанавливает начальное значение для генератора случайных чисел, что обеспечивает воспроизводимость результатов.\n",
    "    #learning_rate=0.1,             # Темп обучения. Более низкое значение помогает улучшить стабильность и уменьшить вероятность переобучения.\n",
    "    #depth=6,                       # Глубина каждого дерева. Меньшая глубина снижает вероятность переобучения.\n",
    "    #l2_leaf_reg=3.0,               # Коэффициент L2-регуляризации на веса в листьях. Увеличивает штраф за большие веса и снижает переобучение.\n",
    "    #bagging_temperature=1.0,       # Параметр, контролирующий интенсивность случайности в выборке для каждого дерева. Чем выше значение, тем больше разнообразие деревьев.\n",
    "    #rsm=0.8,                       # Доля признаков, используемых при обучении каждого дерева. Значение меньше 1 уменьшает переобучение.\n",
    "    #subsample=0.8,                 # Доля данных, используемых для каждого дерева. Чем меньше значение, тем сильнее регуляризация и выше разнообразие деревьев.\n",
    "    #verbose=0                      # Отключает вывод в консоль.\n",
    ")\n",
    "\n",
    "# Добавляем валидационную выборку как eval_set и используем early_stopping\n",
    "cb_model.fit(X_train_selected, y_train, eval_set=(X_val_selected, y_val), early_stopping_rounds=50)"
   ],
   "id": "8570159740e2aa6c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "y_pred = pd.DataFrame(cb_model.predict(X_test_selected), index=X_test_selected.index, columns=['predicted_close'])\n",
    "y_pred"
   ],
   "id": "9e67ee67f59c29a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "y_test.tail(3)",
   "id": "bca08f4e45c4e11e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "y_pred.tail(3)",
   "id": "6ad21b4f1580275e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "all_predictions = y_pred#['predicted_close']\n",
    "all_targets = y_test#['close']\n",
    "plot(all_predictions, all_targets, \"ML model Predictions vs. Actual\")"
   ],
   "id": "e874faa0cf6e140"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "!pip install optuna -q\n",
    "import optuna"
   ],
   "id": "55aeb12b2d38293f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Функция цели для оптимизации гиперпараметров CatBoost с учетом переобучения\n",
    "def objective(trial):\n",
    "    # Определяем гиперпараметры для поиска\n",
    "    # params = {\n",
    "    #     #'iterations': trial.suggest_int('iterations', 100, 1000, 10000),\n",
    "    #     #'depth': trial.suggest_int('depth', 3, 10),\n",
    "    #     'depth': trial.suggest_int('depth', 9, 15),\n",
    "    #     #'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.02, 0.3),\n",
    "    #     'learning_rate': trial.suggest_discrete_uniform('learning_rate', 0.001, 0.02, 0.001),\n",
    "    #     #'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),\n",
    "    #     'l2_leaf_reg': trial.suggest_discrete_uniform('l2_leaf_reg', 1.0, 5.5, 0.5),\n",
    "    #     'min_child_samples': trial.suggest_categorical('min_child_samples', [1, 4, 8, 16, 32]),\n",
    "    #     'grow_policy': 'Depthwise',\n",
    "    #     'iterations': 1000,\n",
    "    #     'use_best_model': True,\n",
    "    #     'eval_metric': 'RMSE',\n",
    "    #     'od_type': 'iter',\n",
    "    #     'od_wait': 20,\n",
    "    #     #'bagging_temperature': trial.suggest_uniform('bagging_temperature', 0, 1),\n",
    "    #     #'rsm': trial.suggest_uniform('rsm', 0.5, 1.0),\n",
    "    #     #'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
    "    #     'random_seed': COMMON_CONFIG.SEED,\n",
    "    #     'verbose': 0,\n",
    "    #     #'early_stopping_rounds': 50\n",
    "    # }\n",
    "    \n",
    "    params = {\n",
    "        \"iterations\": 1000,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 1, 10),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.05, 1.0),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 100),\n",
    "    }\n",
    "    \n",
    "    # Инициализация модели с заданными параметрами\n",
    "    cb_model = cb.CatBoostRegressor(**params)\n",
    "\n",
    "    # Обучение модели с валидационной выборкой\n",
    "    cb_model.fit(X_train_selected.copy(), y_train.copy(), eval_set=(X_val_selected.copy(), y_val.copy()), early_stopping_rounds=100, verbose=0)\n",
    "    \n",
    "    loss = mean_squared_error(y_test, cb_model.predict(X_test_selected.copy()), squared=False)\n",
    "    return loss\n",
    "    \n",
    "    # Предсказания на тренировочной и валидационной выборках\n",
    "    #y_train_pred = cb_model.predict_proba(X_train_selected)[:, 1]\n",
    "    #y_val_pred = cb_model.predict_proba(X_val_selected)[:, 1]\n",
    "    \n",
    "    # Оценка метрики ROC AUC на тренировочной и валидационной выборках\n",
    "    #train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "    #val_auc = roc_auc_score(y_val, y_val_pred)\n",
    "    \n",
    "    # Штраф за переобучение (разница между тренировочной и валидационной метриками)\n",
    "    #overfitting_penalty = abs(train_auc - val_auc)\n",
    "    \n",
    "    # Целевая функция с учетом штрафа: при переобучении функция уменьшится\n",
    "    #score = val_auc - overfitting_penalty\n",
    "    \n",
    "    #return score"
   ],
   "id": "87c6afdd54d12659"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Создаем объект исследования\n",
    "study = optuna.create_study(direction='minimize')#direction='maximize')\n",
    "study.optimize(objective, n_trials=10, n_jobs=-1)  \n",
    "\n",
    "# Получаем лучшие параметры и результат\n",
    "best_cb_model_params = study.best_params\n",
    "best_loss = study.best_value\n",
    "\n",
    "print(\"Лучшие параметры:\", best_cb_model_params)\n",
    "print(\"Лучший Loss:\", best_loss)"
   ],
   "id": "92d1e04e6e90bb0e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "optuna.visualization.plot_optimization_history(study)",
   "id": "951070d20887005e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Инициализация модели CatBoostClassifier с оптимальными гиперпараметрами\n",
    "optimal_params = study.best_params\n",
    "cb_model = cb.CatBoostRegressor(\n",
    "    **optimal_params,\n",
    "    random_seed=COMMON_CONFIG.SEED,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Обучение модели на тренировочной выборке с валидационной проверкой для контроля\n",
    "cb_model.fit(X_train_selected, y_train, eval_set=(X_val_selected, y_val), early_stopping_rounds=50, verbose=0)"
   ],
   "id": "c7b57c6583ef1a09"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "y_pred = pd.DataFrame(cb_model.predict(X_test_selected), index=X_test_selected.index, columns=['predicted_close'])\n",
    "y_pred"
   ],
   "id": "fe82a46d0ec30a6a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "all_predictions = y_pred#['predicted_close']\n",
    "all_targets = y_test#['close']\n",
    "plot(all_predictions, all_targets, \"ML model Predictions vs. Actual\")"
   ],
   "id": "e2a9121598bf1343"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
